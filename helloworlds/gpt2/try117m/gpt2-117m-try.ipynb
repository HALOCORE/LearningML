{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{x}{y}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/w/wangbo20/git_repos/_readonly/gpt-2/models/117M/\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "files inside gpt2/models/117M:\n",
    "\n",
    "-rw-r--r-- 1 wangbo20 grad    77 Sep 16 11:29 checkpoint\n",
    "-rw-r--r-- 1 wangbo20 grad 1018K Sep 16 11:29 encoder.json\n",
    "-rw-r--r-- 1 wangbo20 grad    90 Sep 16 11:29 hparams.json\n",
    "-rw-r--r-- 1 wangbo20 grad  475M Sep 16 11:29 model.ckpt.data-00000-of-00001\n",
    "-rw-r--r-- 1 wangbo20 grad  5.1K Sep 16 11:29 model.ckpt.index\n",
    "-rw-r--r-- 1 wangbo20 grad  461K Sep 16 11:29 model.ckpt.meta\n",
    "-rw-r--r-- 1 wangbo20 grad  446K Sep 16 11:29 vocab.bpe\n",
    "\"\"\"\n",
    "\n",
    "model_pos=\"/home/w/wangbo20/git_repos/_readonly/gpt-2/models/117M/\"\n",
    "print(model_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"distilgpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9cf4c075c9c4206b2dada977b85e0ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=762.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2b0fa387e643809295fe538522d498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=352833716.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained('distilgpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The girl is a => [464, 2576, 318, 257]\n",
      "predicted index is:  2576\n",
      "decode directly is:   girl\n",
      "decode with sentence is:  The girl is a girl\n",
      "\n",
      "The girl is a girl => [464, 2576, 318, 257, 2576]\n",
      "predicted index is:  508\n",
      "decode directly is:   who\n",
      "decode with sentence is:  The girl is a girl who\n",
      "\n",
      "The girl is a girl who => [464, 2576, 318, 257, 2576, 508]\n",
      "predicted index is:  318\n",
      "decode directly is:   is\n",
      "decode with sentence is:  The girl is a girl who is\n",
      "\n",
      "The girl is a girl who is => [464, 2576, 318, 257, 2576, 508, 318]\n",
      "predicted index is:  257\n",
      "decode directly is:   a\n",
      "decode with sentence is:  The girl is a girl who is a\n",
      "\n",
      "The girl is a girl who is a => [464, 2576, 318, 257, 2576, 508, 318, 257]\n",
      "predicted index is:  2576\n",
      "decode directly is:   girl\n",
      "decode with sentence is:  The girl is a girl who is a girl\n",
      "\n",
      "The girl is a girl who is a girl => [464, 2576, 318, 257, 2576, 508, 318, 257, 2576]\n",
      "predicted index is:  508\n",
      "decode directly is:   who\n",
      "decode with sentence is:  The girl is a girl who is a girl who\n",
      "\n",
      "The girl is a girl who is a girl who => [464, 2576, 318, 257, 2576, 508, 318, 257, 2576, 508]\n",
      "predicted index is:  318\n",
      "decode directly is:   is\n",
      "decode with sentence is:  The girl is a girl who is a girl who is\n",
      "\n",
      "The girl is a girl who is a girl who is => [464, 2576, 318, 257, 2576, 508, 318, 257, 2576, 508, 318]\n",
      "predicted index is:  257\n",
      "decode directly is:   a\n",
      "decode with sentence is:  The girl is a girl who is a girl who is a\n",
      "\n",
      "The girl is a girl who is a girl who is a => [464, 2576, 318, 257, 2576, 508, 318, 257, 2576, 508, 318, 257]\n",
      "predicted index is:  2576\n",
      "decode directly is:   girl\n",
      "decode with sentence is:  The girl is a girl who is a girl who is a girl\n",
      "\n",
      "--------------------------------\n",
      "The boy is a girl who is a boy who is a => [464, 2933, 318, 257, 2576, 508, 318, 257, 2933, 508, 318, 257]\n",
      "predicted index is:  2576\n",
      "decode directly is:   girl\n",
      "decode with sentence is:  The boy is a girl who is a boy who is a girl\n",
      "\n",
      "The girl is a boy who is a girl who is a => [464, 2576, 318, 257, 2933, 508, 318, 257, 2576, 508, 318, 257]\n",
      "predicted index is:  2576\n",
      "decode directly is:   girl\n",
      "decode with sentence is:  The girl is a boy who is a girl who is a girl\n",
      "\n",
      "The boy is a boy who is a girl who is a => [464, 2933, 318, 257, 2933, 508, 318, 257, 2576, 508, 318, 257]\n",
      "predicted index is:  2576\n",
      "decode directly is:   girl\n",
      "decode with sentence is:  The boy is a boy who is a girl who is a girl\n",
      "\n",
      "The girl is a boy who is a boy who is a => [464, 2576, 318, 257, 2933, 508, 318, 257, 2933, 508, 318, 257]\n",
      "predicted index is:  2933\n",
      "decode directly is:   boy\n",
      "decode with sentence is:  The girl is a boy who is a boy who is a boy\n",
      "\n",
      "--------------------------------\n",
      "The girl is my => [464, 2576, 318, 616]\n",
      "predicted index is:  1545\n",
      "decode directly is:   friend\n",
      "decode with sentence is:  The girl is my friend\n",
      "\n",
      "The tree is a evil => [464, 5509, 318, 257, 6181]\n",
      "predicted index is:  5509\n",
      "decode directly is:   tree\n",
      "decode with sentence is:  The tree is a evil tree\n",
      "\n",
      "Who's the girl on the => [8241, 338, 262, 2576, 319, 262]\n",
      "predicted index is:  3002\n",
      "decode directly is:   cover\n",
      "decode with sentence is:  Who's the girl on the cover\n",
      "\n",
      "Who's the boy under the => [8241, 338, 262, 2933, 739, 262]\n",
      "predicted index is:  1323\n",
      "decode directly is:   bus\n",
      "decode with sentence is:  Who's the boy under the bus\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def next_word(text):\n",
    "    indexed_tokens = tokenizer.encode(text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    print(text, \"=>\", indexed_tokens)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor)\n",
    "        predictions = outputs[0]\n",
    "\n",
    "    predicted_index = torch.argmax(predictions[0, -1, :]).item()\n",
    "    print(\"predicted index is: \", predicted_index)\n",
    "    print(\"decode directly is: \", tokenizer.decode([predicted_index]))\n",
    "    print(\"decode with sentence is: \", tokenizer.decode(indexed_tokens + [predicted_index]))\n",
    "    print()\n",
    "\n",
    "next_word(\"The girl is a\")\n",
    "next_word(\"The girl is a girl\")\n",
    "next_word(\"The girl is a girl who\")\n",
    "next_word(\"The girl is a girl who is\")\n",
    "next_word(\"The girl is a girl who is a\")\n",
    "next_word(\"The girl is a girl who is a girl\")\n",
    "next_word(\"The girl is a girl who is a girl who\")\n",
    "next_word(\"The girl is a girl who is a girl who is\")\n",
    "next_word(\"The girl is a girl who is a girl who is a\")\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "\n",
    "next_word(\"The boy is a girl who is a boy who is a\")\n",
    "next_word(\"The girl is a boy who is a girl who is a\")\n",
    "next_word(\"The boy is a boy who is a girl who is a\")\n",
    "next_word(\"The girl is a boy who is a boy who is a\")\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "\n",
    "next_word(\"The girl is my\")\n",
    "next_word(\"The tree is a evil\")\n",
    "next_word(\"Who's the girl on the\")\n",
    "next_word(\"Who's the boy under the\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "#include <std => [2, 17256, 1279, 19282]\n",
      "predicted index is:  952\n",
      "decode directly is:  io\n",
      "decode with sentence is:  #include <stdio\n",
      "\n",
      "#include <stdio => [2, 17256, 1279, 19282, 952]\n",
      "predicted index is:  13\n",
      "decode directly is:  .\n",
      "decode with sentence is:  #include <stdio.\n",
      "\n",
      "#include <stdio. => [2, 17256, 1279, 19282, 952, 13]\n",
      "predicted index is:  71\n",
      "decode directly is:  h\n",
      "decode with sentence is:  #include <stdio.h\n",
      "\n",
      "#include <stdio.h => [2, 17256, 1279, 19282, 952, 13, 71]\n",
      "predicted index is:  29\n",
      "decode directly is:  >\n",
      "decode with sentence is:  #include <stdio.h>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------------------\")\n",
    "\n",
    "next_word(\"#include <std\")\n",
    "next_word(\"#include <stdio\")\n",
    "next_word(\"#include <stdio.\")\n",
    "next_word(\"#include <stdio.h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}