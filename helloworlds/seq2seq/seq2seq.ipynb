{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "import numpy as np\n",
    "import spacy\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter # to print to tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_ger = spacy.load('de_core_news_sm')\n",
    "spacy_eng = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[&#39;Hello&#39;, &#39;are&#39;, &#39;you&#39;, &#39;OK&#39;, &#39;?&#39;]\n"
    }
   ],
   "source": [
    "def tokenizer_ger(text):\n",
    "    return [tok.text for tok in spacy_ger.tokenizer(text)]\n",
    "\n",
    "def tokenizer_eng(text):\n",
    "    return [token.text for token in spacy_eng.tokenizer(text)]\n",
    "\n",
    "print(tokenizer_eng(\"Hello are you OK?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "german = Field(tokenize=tokenizer_ger, lower=True, init_token='<sos>', eos_token='<eos>')\n",
    "english = Field(tokenize=tokenizer_eng, lower=True, init_token='<sos>', eos_token='<eos>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, validation_data, test_data = Multi30k.splits(exts=('.de', '.en'), fields=(german, english))\n",
    "german.build_vocab(train_data, max_size=10000, min_freq=2)\n",
    "english.build_vocab(train_data, max_size=10000, min_freq=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, dropout_p):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dropout_p)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (seq_length, N) N is batch size\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (seq_length, N, embedding_size)\n",
    "        outputs, (hidden, cell) = self.rnn(embedding)\n",
    "        return hidden, cell\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    # input_size: english vocab\n",
    "    # output_size should same as input_size\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, dropout_p):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dropout_p)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        # shape of x: (N) but we want (1,N)\n",
    "        x = x.unsqueeze(0)\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
    "        # shape of outputs: (1, N, hidden_size)\n",
    "        predictions = self.fc(outputs)\n",
    "        # shape of predictions: (1, N, length_of_vocab)\n",
    "        predictions = predictions.squeeze(0)\n",
    "        return predictions, hidden, cell\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        batch_size = source.shape[1]\n",
    "        # (trg_len, N)\n",
    "        target_len = target.shape[0]\n",
    "        target_vocab_size = len(english.vocab)\n",
    "\n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
    "\n",
    "        hidden, cell = self.encoder(source)\n",
    "\n",
    "        # grab start token\n",
    "        x = target[0]\n",
    "        for t in range(1, target_len):\n",
    "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
    "            outputs[t] = output\n",
    "            # (N, english_vocab_size)\n",
    "            best_guess = output.argmax(1)\n",
    "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 0 / 16\nCurrent Time = 15:01:55\nEpoch 1 / 16\nCurrent Time = 15:03:25\nEpoch 2 / 16\nCurrent Time = 15:04:56\nEpoch 3 / 16\nCurrent Time = 15:06:27\nEpoch 4 / 16\nCurrent Time = 15:07:57\nEpoch 5 / 16\nCurrent Time = 15:09:29\nEpoch 6 / 16\nCurrent Time = 15:11:00\nEpoch 7 / 16\nCurrent Time = 15:12:30\nEpoch 8 / 16\nCurrent Time = 15:14:01\nEpoch 9 / 16\nCurrent Time = 15:15:32\nEpoch 10 / 16\nCurrent Time = 15:17:02\nEpoch 11 / 16\nCurrent Time = 15:18:33\nEpoch 12 / 16\nCurrent Time = 15:20:04\nEpoch 13 / 16\nCurrent Time = 15:21:35\nEpoch 14 / 16\nCurrent Time = 15:23:06\nEpoch 15 / 16\nCurrent Time = 15:24:37\nCurrent Time = 15:26:08\n"
    }
   ],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def print_time():\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "\n",
    "num_epochs = 16\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "load_model = False\n",
    "device = torch.device('cuda')\n",
    "input_size_encoder = len(german.vocab)\n",
    "input_size_decoder = len(english.vocab)\n",
    "output_size = len(english.vocab)\n",
    "encoder_embedding_size = 300\n",
    "decoder_embedding_size = 300\n",
    "hidden_size = 1024\n",
    "num_layers = 2\n",
    "enc_dropout = 0.5\n",
    "dec_dropout = 0.5\n",
    "\n",
    "writer = SummaryWriter(f'runs/loss_plot')\n",
    "step = 0\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, validation_data, test_data), \n",
    "    batch_size=batch_size,\n",
    "    sort_within_batch=True,\n",
    "    sort_key = lambda x : len(x.src),\n",
    "    device=device)\n",
    "\n",
    "encoder_net = Encoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout).to(device)\n",
    "decoder_net = Decoder(input_size_decoder, decoder_embedding_size, hidden_size, output_size, num_layers, dec_dropout).to(device)\n",
    "model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "pad_idx = english.vocab.stoi['<pad>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch} / {num_epochs}')\n",
    "    print_time()\n",
    "    for batch_idx, batch in enumerate(train_iterator):\n",
    "        inp_data = batch.src.to(device)\n",
    "        target = batch.trg.to(device)\n",
    "        output = model(inp_data, target)\n",
    "        # output shape: (trg_len, batch_size, output_dim)\n",
    "        output = output[1:].reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        optimizer.step()\n",
    "\n",
    "        writer.add_scalar('Training Loss', loss,global_step=step)\n",
    "        step += 1\n",
    "\n",
    "# final save\n",
    "print_time()\n",
    "to_save = {\"step\": step, 'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict()}\n",
    "torch.save(to_save, f'.models/{step}.save')\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}